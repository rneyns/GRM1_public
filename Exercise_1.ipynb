{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/rneyns/GRM1/blob/master/GRM1.ipynb",
      "authorship_tag": "ABX9TyPMXaoVVWNX1OrVahxX7JuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rneyns/GRM1_public/blob/master/Exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JxM-KUkh13f"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf GRM1\n",
        "!git clone --single-branch --depth=1 --branch master https://github.com/rneyns/GRM1_public\n",
        "!pip3 uninstall seaborn\n",
        "!pip3 install seaborn==0.11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F-wNFGrSASz"
      },
      "source": [
        "#GRM1 practical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz9EqUHhSNZ7"
      },
      "source": [
        "##Preliminary data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j8ooDlMSWaV"
      },
      "source": [
        "First we will load and visualise the composite sattelite image and the data-set that were created in the previous part of the exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRlNWf6pS3Tf"
      },
      "source": [
        "#import the necessary packages\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from GRM1_public.Utility_functions import *\n",
        "\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_LX0V-Fl812"
      },
      "source": [
        "### Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6cff2sBSVpF"
      },
      "source": [
        "#load the data\n",
        "data = pd.read_csv('INSERT PATH HERE')\n",
        "\n",
        "#print the first 5 entries of the dataframe\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk4ZhQstb9Mx"
      },
      "source": [
        "#remove the outliers\n",
        "data = data[data['b_1'] <= 18000] #drop the outliers caused by atmospheric correction\n",
        "data = data[data['b_5'] <= 18000]\n",
        "data = data[data['b_6'] <= 18000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgzMhFAncJ7M"
      },
      "source": [
        "The following lines of code allow you to plot the distribution of the different classes with respect to the different bands. Additionally, a scatterplot is created for each pair of bands.\n",
        "\n",
        "To improve the visualisation for the report, it possible to only plot the classes/bands that show the most interesting patters. To limit the number of bands that is included in the visualisation, adjust the data parameter. More specifically, exclude the names of the columns that you wish to leave out.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXzIVfnAadaD"
      },
      "source": [
        "#plot the distribution of the training data\n",
        "sns.pairplot(data=data[['id','b_1','b_2','b_3','b_4','b_5','b_6']],\n",
        "             kind=\"scatter\", hue=\"id\", plot_kws=dict(s=20, edgecolor=\"white\", linewidth=1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrVV-pEv53KJ"
      },
      "source": [
        "#The visualisation of the distribution over 1 band can also be made separately\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "sns.kdeplot(data=data, x='b_2', hue=\"id\",ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wgUXMYQ_qWr"
      },
      "source": [
        "#Or even one band and one class\n",
        "fig,ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "data_vis = data.loc[data['id'] == 1] #Specify the class you want to visualise\n",
        "sns.histplot(data = data_vis,x = 'b_2', kde=True,ax=ax) #Specify the band you want to visualise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJgyB5can8sJ"
      },
      "source": [
        "#Finally, the scatterplots can also be shown in isolation\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "sns.scatterplot(data=data, x=\"b_2\", y=\"b_3\", hue=\"id\",ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb9WmLWA2YED"
      },
      "source": [
        "#Visualisation of the spectral signatures\n",
        "\n",
        "#Drop unncessary columns when needed, the dataframe should only contain the class identifier and the band values\n",
        "data_vis = data\n",
        "#data_vis = data.drop(['UNNECESSARY COLUMN'], axis=1)\n",
        " \n",
        "\n",
        "#Take the mean value for each value per class and plot it\n",
        "data_mean = data_vis.groupby('id').mean() \n",
        "plot_spectral_signature(data_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrE98-pSmCZc"
      },
      "source": [
        "### ROI data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMx7vYOpVorO"
      },
      "source": [
        "#import the gdal python package\n",
        "import gdal\n",
        "\n",
        "#load the GeoTIFF file (composite sattelite image)\n",
        "raster_file = 'INSERT PATH HERE' \n",
        "driverTiff = gdal.GetDriverByName('GTiff') \n",
        "raster = gdal.Open(raster_file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca19vZc3XYt0"
      },
      "source": [
        "#convert the gdal raster file to a pandas dataframe, this makes it easier to handle\n",
        "nbands = raster.RasterCount \n",
        "data_raster = np.empty((raster.RasterXSize*raster.RasterYSize, nbands))\n",
        "\n",
        "for i in range(1, nbands+1): \n",
        "    band = raster.GetRasterBand(i).ReadAsArray() \n",
        "    data_raster[:, i-1] = band.flatten()\n",
        "\n",
        "data_raster = pd.DataFrame(data_raster)\n",
        "data_raster.columns = ['b1','b2','b3','b4','b5','b7']\n",
        "\n",
        "\n",
        "data_raster.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqA8s0J6Yue_"
      },
      "source": [
        "Now you will plot a pairplot for the full raster, so you can compare the distribution with your training-set. I advice you to save this image once the visualisation is generated so you don't have to run it again (it takes some time). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQ-9PWiR-Ab"
      },
      "source": [
        "#remove the outliers before visualisation\n",
        "data_raster_vis = data_raster[data_raster[ ['b1','b2','b3','b4','b5','b7']] <= 18000]\n",
        "\n",
        "sns.pairplot(data=data_raster_vis,\n",
        "             kind=\"scatter\", plot_kws=dict(s=40, edgecolor=\"white\", linewidth=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMwB0n3tTUrE"
      },
      "source": [
        "##Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oRkxb91jTUq"
      },
      "source": [
        "You will train three classification algorithms on our data-set: a K-means classifier, a maximum likelihood classifier and a classifier of your choice. For each classifier, we will make use of the overall accuracy, the confusion matrix and the kappa-value to assess the results. Based on the confusion matrix you can subsequently derive the other accuracy measures we ask for in the report. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfiaGLNInSnc"
      },
      "source": [
        "#load validation data\n",
        "val = pd.read_csv('INSERT PATH HERE')\n",
        "val = val[val['b_1'] <= 18000] #drop the outliers caused by atmospheric correction\n",
        "val = val[val['b_5'] <= 18000] \n",
        "val = val[val['b_6'] <= 18000] \n",
        "val.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m61tkQRgvTqz"
      },
      "source": [
        "#split both sets in input and label sets, the data is also transformed to a numpy array so it can be used in scikit-learn\n",
        "train_x = data[['b_1','b_2','b_3','b_4','b_5','b_6']].values\n",
        "train_y = data[['id']].values\n",
        "\n",
        "val_x = val[['b_1','b_2','b_3','b_4','b_5','b_6']].values\n",
        "val_y = val[['id']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR5idxuSKtYL"
      },
      "source": [
        "#change datatypes of the b_columns if necessary\n",
        "val[['b_1','b_2','b_3','b_4','b_5','b_6']] = val[['b_1','b_2','b_3','b_4','b_5','b_6']].astype(float)\n",
        "data[['b_1','b_2','b_3','b_4','b_5','b_6']] = data[['b_1','b_2','b_3','b_4','b_5','b_6']].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DfqUyoj9pOY"
      },
      "source": [
        "### Minimum distance to means classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im0JQDHJ9xwY"
      },
      "source": [
        "#Initialise and train the model\n",
        "clf1 = NearestCentroid()\n",
        "clf1.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDNms8fnCWb2"
      },
      "source": [
        "#### Accuracy assessment\n",
        "Below, you will use three metrics to assess the performance of your model on the validation set:\n",
        "\n",
        "- Overall accuracy\n",
        "- The confusion matrix\n",
        "- Cohen's Kappa value\n",
        "\n",
        "Based on the confusion matrix you are also expected to calculate the users and producers accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0K3ThUNBtEW"
      },
      "source": [
        "#apply the classifier to the training and validation set and assess the overall accuracy\n",
        "predictions1 = clf1.predict(train_x)\n",
        "acc_train = accuracy_score(train_y,predictions1)\n",
        "\n",
        "predictions_val1 = clf1.predict(val_x)\n",
        "acc_val = accuracy_score(val_y,predictions_val1)\n",
        "\n",
        "print('The overall accuracy score is %.3f for the training set and %.3f on the validation set' % (acc_train,acc_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQFyhHxrBzxg"
      },
      "source": [
        "#now plot the normalized confusion matrix \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "disp = plot_confusion_matrix(clf1, val_x, val_y,\n",
        "                                  cmap=plt.cm.Blues,\n",
        "                                  normalize=None,ax=ax,values_format=\".0f\")\n",
        "disp.ax_.set_title((\"Confusion matrix\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeEfQHFrB1EB"
      },
      "source": [
        "#next, calculate the kappa-value\n",
        "\n",
        "Kappa = cohen_kappa_score(predictions_val1, val_y)\n",
        "print('The Kappa value for your classification is: %.3f for the validation set' % (Kappa))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soKOc4fVgpVC"
      },
      "source": [
        "The final block of code will export the result of the classification to a GeoTIFF file which can be opened in QGIS. Use this to make a nice map/visualisation of your results. \n",
        "\n",
        "Once the code has been run, the geotiff will become available in the 'files' section on the left (it might be necessary to refresh first)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LoD7CQCB_PK"
      },
      "source": [
        "#export the result to GeoTIFF\n",
        "to_GeoTIFF(out_name = \"dist_mean.tif\", clf = clf1, data = data_raster, raster = raster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd73qP2BEHLr"
      },
      "source": [
        "### Maximum likelihood classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMV2fPKLEL71"
      },
      "source": [
        "#Initialise and train the model\n",
        "clf2 = GaussianNB()\n",
        "clf2.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNqsj4cXF8Vn"
      },
      "source": [
        "#### Accuracy assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-eORLvmFfJF"
      },
      "source": [
        "#apply the classifier to the training and validation set and assess the overall accuracy\n",
        "predictions2 = clf2.predict(train_x)\n",
        "acc_train = accuracy_score(train_y,predictions2)\n",
        "\n",
        "predictions_val2 = clf2.predict(val_x)\n",
        "acc_test = accuracy_score(val_y,predictions_val2)\n",
        "\n",
        "print('The overall accuracy score is %.3f for the training set and %.3f on the validation set' % (acc_train,acc_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzDKmas0MD-t"
      },
      "source": [
        "#now plot the normalized confusion matrix \n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "disp = plot_confusion_matrix(clf2, val_x, val_y,\n",
        "                                  cmap=plt.cm.Blues,\n",
        "                                  normalize=None,ax=ax,values_format=\".0f\")\n",
        "disp.ax_.set_title((\"Confusion matrix\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sko70oNFlK1"
      },
      "source": [
        "#next, calculate the kappa-value\n",
        "Kappa = cohen_kappa_score(predictions_val2, val_y)\n",
        "print('The Kappa value for your classification is: %.3f for the validation set' % (Kappa))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS-XDS__Fr9P"
      },
      "source": [
        "to_GeoTIFF(out_name = \"ML.tif\", clf = clf2, data = data_raster, raster = raster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xFl8tmCMba9"
      },
      "source": [
        "### Third classifiction agorithm\n",
        "Throughout the third session for exercise 1 you are expected to implement a third classification algorithm that you have encountered during the lectures. To do this you will use the same python package that was used for the first 2 classification algorithms: \"scikit-learn\". \n",
        "Extensive documentation on the different algorithms available within this package can be found at: https://scikit-learn.org/stable/supervised_learning.html\n",
        "\n",
        "An overview of the possible algorithms can be seen in the following table:\n",
        "\n",
        "Algorithm | Documentation\n",
        "---|---\n",
        "Artificial neural network | https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
        "Decision tree classifier | https://scikit-learn.org/stable/modules/tree.html\n",
        "Random forest | https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
        "K-Nearest neighbour | https://scikit-learn.org/stable/modules/neighbors.html\n",
        "\n",
        "\n",
        "\n",
        "Below I provide you some code on how to set-up a classification algorithm, fill in the necessary parameters/variables. An example on how to import a specific classifier can always be found in the documentation.  \n",
        "\n",
        "HINT: an artificial neural network is also often referred to as a multi-layer perceptron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH6MGNk-QbzD"
      },
      "source": [
        "#replace ALGORITHM by the algorithm you have selected and PACKAGE by the package in which it can be found.\n",
        "#A full example of the import code for each algorithm can be found in the documentation of sklearn\n",
        "from sklearn.PACKAGE import ALGORITHM\n",
        "\n",
        "#Define the classifier \n",
        "clf3 = ALGORITHM() #fill in algorithm by the algorithm you just imported (don't forget the brackets)\n",
        "\n",
        "#Train the classifier on the training set\n",
        "clf3.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPU4-ZBTW0y"
      },
      "source": [
        "#### Accuracy assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBvL7uGYTUJG"
      },
      "source": [
        "#apply the classifier to the training and validation set and assess the overall accuracy\n",
        "predictions3 = clf3.predict(train_x)\n",
        "acc_train = accuracy_score(train_y,predictions3)\n",
        "\n",
        "predictions_val3 = clf3.predict(val_x)\n",
        "acc_val = accuracy_score(val_y,predictions_val3)\n",
        "\n",
        "print('The overall accuracy score is %.3f for the training set and %.3f on the validation set' % (acc_train,acc_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIzMYHfKTaxr"
      },
      "source": [
        "#now plot the normalized confusion matrix \n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "disp = plot_confusion_matrix(clf3, val_x, val_y,\n",
        "                                  cmap=plt.cm.Blues,\n",
        "                                  normalize=None,ax=ax,values_format=\".0f\")\n",
        "disp.ax_.set_title((\"Confusion matrix\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkglTgKPTfcu"
      },
      "source": [
        "#next, calculate the kappa-value\n",
        "Kappa = cohen_kappa_score(predictions_val3, val_y)\n",
        "print('The Kappa value for your classification is: %.3f for the validation set' % (Kappa))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSu-5x08TiCo"
      },
      "source": [
        "to_GeoTIFF(out_name = \"ML.tif\", clf = clf3, data = data_raster, raster = raster)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}